{
    "publications" : [
        {
            "id": "1",
            "title": "Bio-inspired Distributed Neural Locomotion Controller (D-NLC) for Robust Locomotion and Emergent Behaviors",
            "authors": "Zhikai Zhang, Siqi Guo, Henry Kou, Ishayu Shikhare, Howie Choset, Lu Li.",
            "abstract": "With relatively fewer neurons than more complex life forms, insects are still capable of producing astonishing locomotive behaviors, such as traversing diverse habitats and making rapid gait adaptations after extreme injury or autotomy. Biologists attribute this to a chain of segmental neuron clusters (ganglia) within insect nervous systems, which act as distributed, self-organizing sensorimotor control units. Inspired by the neural structure of the \textit{Carausius morosus}, the common stick insect, this research introduces the Distributed Neural Locomotion Controller (D-NLC), a modular control framework utilizing local proprioceptive feedback to modulate joint-level Central Pattern Generator (CPG) signals to produce emergent locomotive behaviors. We implemented this framework using a modular legged robot with distributed joint-level embedded computing units and assessed its performance and behavior under various experimental settings. Based on real-world experiments, we observe an overall 31.3% average increase in curvilinear motion performance under external (terrain) and internal (amputation) disturbances compared to a centralized predefined gait controller. This difference is statistically significant (P$<<0.05$) for larger perturbations but not for single-leg amputations. Experiments with perturbation-induced leg stance duration and leg-phase-difference analysis further validated our hypothesis regarding D-NLC's role in the robust perceptive locomotion and self-emergent gait adaptation against complex unforeseen perturbations. This proposed control framework does not require any numerical optimization or weight training processes, which are time-consuming and computationally expensive. To the best of our knowledge, this framework is the first bio-inspired neural controller deployed on a distributed embedded system.",
            "paperurl": "",
            "venue": "(submitted to) 2025 ICRA",
            "year": "2024",
            "date": "",
            "bib": ""
        },
        {
            "id": "2",
            "title": "Backdoor attacks on unsupervised graph representation learning",
            "authors": "Bingdao, F., Di, J., Xiaobao, W., Fangyu, C., Siqi, G.",
            "abstract": "Unsupervised graph learning techniques have garnered increasing interest among researchers. These methods employ the technique of maximizing mutual information to generate representations of nodes and graphs. We show that these methods are susceptible to backdoor attacks, wherein the adversary can poison a small portion of unlabeled graph data (e.g., node features and graph structure) by introducing triggers into the graph. This tampering disrupts the representations and increases the risk to various downstream applications. Previous backdoor attacks in supervised learning primarily operate directly on the label space and may not be suitable for unlabeled graph data. To tackle this challenge, we introduce GRBA,1 a gradient-based first-order backdoor attack method. To the best of our knowledge, this constitutes a pioneering endeavor in investigating backdoor attacks within the domain of unsupervised graph learning. The initiation of this method does not necessitate prior knowledge of downstream tasks, as it directly focuses on representations. Furthermore, it is versatile and can be applied to various downstream tasks, including node classification, node clustering and graph classification. We evaluate GRBA on state-of-the-art unsupervised learning models, and the experimental results substantiate the effectiveness and evasiveness of GRBA in both node-level and graph-level tasks.",
            "paperurl": "https://pdf.sciencedirectassets.com/271125/1-s2.0-S0893608024X0009X/1-s2.0-S0893608024005926/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEK7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIA1SxNoiGDC8mP8gnELj0%2BsQMYFkJ%2ByuBiw8Q43w9Eu4AiEApNCDBoPvk6%2B6M%2B2EskvOX8t3FhTD%2FAxtQ1E3Y0vM2SIqswUINxAFGgwwNTkwMDM1NDY4NjUiDIoKe0%2BbUeUDhjYBfCqQBSL%2BniBBym8lDx0SxjuvxB6evs%2B%2Fm%2BIrmMtRuvx714f1hqOU83V59EAe6V6qXUd8Huk5qhUmMLigV3eh4W8j9uX%2BSILzJ2HSI41I2MFgoIAcIsdjAvHEjS%2FGOcojMW0s9yqzp18kptZ%2BxwdxQQFYr6oDB%2BCAEmBwUayD6ADtoadtYg2kvwTEK6PZ8ghdFVC8fkuZHnOzGXPkCKqhCpKExCrIgPeF40oN5mbDK0dcw89ZhUflDUn1ASPTl8NM%2FlhQoxZuOFmBRhOTkRicRTD%2FKbnWgvXFIH2fK75RHKf0ejn03JDlK2uDRGvo%2FgTIUe1ZUJJc39emQ0Ak8vkBesxXfR6ldQ2IP6ra23D4IvIAE2T1fiUTIAEk8pHGsyKTDb1EPW62NX%2BeRdsFkB8mm2UYHk5JiRku0Dm00e6tYpuko4df3T7S6BycYUdfehH8vdAZdfBe0zqDoLXFUV7UqD5h6VjF9MQDVEGIYNKX675Ixj7Oyv7zViyuQsXwVdIuU2Jg%2Bihy01MZctKrD4gwBzGsWvgNouWrLj8InbD5Zlqmz3%2FUAkZeq7gBDYQz1S%2BMnhPTr5KMiWUcHIGbIVIrGtlQv8UINMrMyKebYo%2F%2F1X%2FqSik%2BSNNhHqOn5Z8GxgxVMniDRKAZuxPzF8TG8WeTvUMReToxVNRfat71clP6nL2FfSQBJ4uL7t%2BaJJFyNfxQT8OGF3nfkxOH7MpC9rc96077JVfQHzYiedjwUbgGX%2F9j77AFN3Mga9lLS6HWcx1afgz63qpSZ0qjrJPjdsaZ9yU7Ga0z2Tv3XVPX7E3BrRMMYMsuxVlsAX1O1mSDFPSoCx5TTnoFY80RWRJ4kv0LTIFKLSKhX0YlGTtX7P4lZXYmjWfgMN3Fr7kGOrEBlZzG5xfbadvHaG6O3aupi2bw5Xz%2FAOTele1PQWdRH8PdgonQ4ibOAwG%2BjPPKeM%2FuEqJPxfSGQaNSUdQXGrR8cij3UEjagOjlnLqcOmgf%2FHN%2FPUK9%2F5lGuCnxbqtJmEwkdJsbPV%2B%2FRTO8CXgvJ4sIeKqbp2RlkoAYGCWX8xEagucnH%2BxJWeYzEVI7jWFqoex1zTAjVIc2jr521GrtDh4lbGaEUAyxgx0oGkJdcS2Yad1T&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20241106T220434Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY755QP7L6%2F20241106%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=aa15c0939cabc12d054aeb0d5bc1db0455d2e727ff6b97e768df910ebeedefc7&hash=be22c67d31f88e7f26b7ea8c27bfff41f30024ccd88dd0d1d67d3335203f6a82&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0893608024005926&tid=spdf-1f2fdb58-9171-46d3-a622-37c66fa31391&sid=02329e929b69244ee49b9ea22a661c0ebc0agxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f155d07025756535a5c0c&rr=8de86149bbe96179&cc=us",
            "venue": "Journal Neural Networks",
            "year": "2024",
            "date": "2024-08-10",
            "bib": "@article{FENG2024106668,\ntitle = {Backdoor attacks on unsupervised graph representation learning},\njournal = {Neural Networks},\nvolume = {180},\npages = {106668},\nyear = {2024},\nissn = {0893-6080},\ndoi = {https://doi.org/10.1016/j.neunet.2024.106668},\nurl = {https://www.sciencedirect.com/science/article/pii/S0893608024005926},\nauthor = {Bingdao Feng and Di Jin and Xiaobao Wang and Fangyu Cheng and Siqi Guo},\nkeywords = {Backdoor attack, Unsupervised graph learning, Trigger},\nabstract = {Unsupervised graph learning techniques have garnered increasing interest among researchers. These methods employ the technique of maximizing mutual information to generate representations of nodes and graphs. We show that these methods are susceptible to backdoor attacks, wherein the adversary can poison a small portion of unlabeled graph data (e.g., node features and graph structure) by introducing triggers into the graph. This tampering disrupts the representations and increases the risk to various downstream applications. Previous backdoor attacks in supervised learning primarily operate directly on the label space and may not be suitable for unlabeled graph data. To tackle this challenge, we introduce GRBA,11https://github.com/fbd3/GRBA.git. a gradient-based first-order backdoor attack method. To the best of our knowledge, this constitutes a pioneering endeavor in investigating backdoor attacks within the domain of unsupervised graph learning. The initiation of this method does not necessitate prior knowledge of downstream tasks, as it directly focuses on representations. Furthermore, it is versatile and can be applied to various downstream tasks, including node classification, node clustering and graph classification. We evaluate GRBA on state-of-the-art unsupervised learning models, and the experimental results substantiate the effectiveness and evasiveness of GRBA in both node-level and graph-level tasks.}\n}"
        },
        {
            "id": "3",
            "title": "Local-Global Defense against Unsupervised Adversarial Attacks on Graphs",
            "authors": "Jin, D., Feng, B., Guo, S., Wang, X., Wei, J., & Wang, Z.",
            "abstract": "Unsupervised pre-training algorithms for graph representation learning are vulnerable to adversarial attacks, such as first-order perturbations on graphs, which will have an impact on particular downstream applications. Designing an effective representation learning strategy against white-box attacks remains a crucial open topic. Prior research attempts to improve representation robustness by maximizing mutual information between the representation and the perturbed graph, which is suboptimal because it does not adapt its defense techniques to the severity of the attack. To address this issue, we propose an unsupervised defense method that combines local and global defense to improve the robustness of representation. Note that we put forward the Perturbed Edges Harmfulness (PEH) metric to determine the riskiness of the attack. Thus, when the edges are attacked, the model can automatically identify the risk of attack. We present a method of attention-based protection against high-risk attacks that penalizes attention coefficients of perturbed edges to encoders. Extensive experiments demonstrate that our strategies can enhance the robustness of representation against various adversarial attacks on three benchmark graphs.",
            "paperurl": "https://ojs.aaai.org/index.php/AAAI/article/view/25979",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 37",
            "year": "2023",
            "date": "2023-06-26",
            "bib": "@article{Jin_Feng_Guo_Wang_Wei_Wang_2023,\ntitle={Local-Global Defense against Unsupervised Adversarial Attacks on Graphs},\nvolume={37},\nurl={https://ojs.aaai.org/index.php/AAAI/article/view/25979},\nDOI={10.1609/aaai.v37i7.25979},\nnumber={7},\njournal={Proceedings of the AAAI Conference on Artificial Intelligence},\nauthor={Jin, Di and Feng, Bingdao and Guo, Siqi and Wang, Xiaobao and Wei, Jianguo and Wang, Zhen},\nyear={2023},\nmonth={Jun.},\npages={8105-8113}\n}"
        },
        {
            "id": "4",
            "title": "Conditional Generative Adversarial Networks: Introduction and Application",
            "authors": "Yichen Ding and Siqi Guo",
            "abstract": "Conditional Generative Adversarial Networks (GANs) play an important role in the field of computer vision. Its strength not only lies in its stronger feature extraction ability than traditional algorithms but also has achieved unprecedented success in the mutual game method of two different neural networks. The so-called dual network in GAN is called generator and discriminator. The generator generates a picture close to the expected value by inputting the deep learning network. The discriminator judges whether the image generated by the generator is true. Therefore, the mutual training purpose of the two models is to generate high-quality images infinitely close to the specified features. This paper mainly analyzes the basic network structure of Conditional GAN and its practical application in the fields of image generation, image style transformation, font style transformation, and natural language processing. Different branches of Conditional GAN and optimization methods such as InfoGAN, CycleGAN, StackGAN, McGAN, Conditional SeqGAN are also described. In general, GAN has an unprecedented impact on computer vision and image processing with NLP. At the same time, it also has great potential for future development.",
            "paperurl": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12348/2641409/Conditional-generative-adversarial-networks-introduction-and-application/10.1117/12.2641409.short",
            "venue": "2nd International Conference on Artificial Intelligence, Automation, and High-Performance Computing (AIAHPC)",
            "year": "2022",
            "date": "2022-11-10",
            "bib": "@inproceedings{10.1117/12.2641409,\nauthor = {Yichen Ding and Siqi Guo},\ntitle = {{Conditional generative adversarial networks: introduction and application}},\nvolume = {12348},\nbooktitle = {2nd International Conference on Artificial Intelligence, Automation, and High-Performance Computing (AIAHPC 2022)},\neditor = {Ligu Zhu},\norganization = {International Society for Optics and Photonics},\npublisher = {SPIE},\npages = {1234811},\nyear = {2022},\ndoi = {10.1117/12.2641409},\nURL = {https://doi.org/10.1117/12.2641409}\n}"
        }
    ]
}