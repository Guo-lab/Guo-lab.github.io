
![Description](../images/projects/cmu_course_project/optimal_rendezvous_docking_mpc_convex.gif){: width=600 height=400 }

- The FTL is designed to manage logical-to-physical address mappings, handle block metadata, and perform garbage collection and wear-leveling to ensure efficient, reliable, and endurable flash memory usage.
- Optimized the FTL with the page-level mapping scheme, compressed metadata storage, and a greedy wear leveling policy to reach minimized write amplification, lower memory cost, and better endurance.
- In previous checkpoints of this project, designed and implemented a Hybrid Log-Block mapping FTL for the simulated SSD. Additionally, benchmarked various Garbage Collection Policies such as Round Robin, LRU, LFS Cost-Benefit.
# Teaser

<video width="600" controls>
  <source src="../videos/projects/cmu_course/bustub.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>

**Nerfies** turns selfie videos from your phone into free-viewpoint portraits.

---

# Results Carousel

- ![Steve Video](../videos/projects/cmu_course/bustub.mp4)
- ![Chair Video](../videos/projects/cmu_course/bustub.mp4)
- ![Shiba Video](../videos/projects/cmu_course/ssd_after_debugging.mp4)

---

# Abstract

We present the first method capable of photorealistically reconstructing a non-rigidly deforming scene using photos/videos captured casually from mobile phones.

Our approach augments neural radiance fields (NeRF) by optimizing an additional continuous volumetric deformation field that warps each observed point into a canonical 5D NeRF. We observe that these NeRF-like deformation fields are prone to local minima, and propose a coarse-to-fine optimization method for coordinate-based models that allows for more robust optimization. By adapting principles from geometry processing and physical simulation to NeRF-like models, we propose an elastic regularization of the deformation field that further improves robustness.

---

# Visual Effects

Using *nerfies* you can create fun visual effects. This Dolly zoom effect would be impossible without nerfies since it would require going through a wall.

![Dolly Zoom Video](../videos/projects/cmu_course/ssd_after_debugging.mp4)

---

# Matting

As a byproduct of our method, we can also solve the matting problem by ignoring samples that fall outside of a bounding box during rendering.

![Matting Video](../videos/projects/cmu_course/ssd_after_debugging.mp4)

---

# Animation

## Re-rendering the input video

Using **Nerfies**, you can re-render a video from a novel viewpoint such as a stabilized camera by playing back the training deformations.

![Replay Video](../videos/projects/cmu_course/ssd_after_debugging.mp4)